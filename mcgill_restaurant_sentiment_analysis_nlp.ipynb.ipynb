{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Score for Google Maps Restaurant Reviews Around McGill\n",
    "\n",
    "Our project implements a sentiment analysis pipeline using VADER + Custom Lexicons (Gen Z vocabulary: English + French).\n",
    "\n",
    "Objective: to examine whether there are differences between the general population and Generation Z in their food consumption around the university, with a particular focus on value for money, defined as the balance between price and quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "#%pip install vaderSentiment\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Inspection, Cleaning and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews CSV Columns:\n",
      "['place_id', 'name', 'primary_type', 'address', 'latitude', 'longitude', 'rating', 'user_rating_count', 'distance_to_center_m', 'review1_rating', 'review1_text', 'review1_author', 'review1_publish_time', 'review2_rating', 'review2_text', 'review2_author', 'review2_publish_time', 'review3_rating', 'review3_text', 'review3_author', 'review3_publish_time', 'review4_rating', 'review4_text', 'review4_author', 'review4_publish_time', 'review5_rating', 'review5_text', 'review5_author', 'review5_publish_time']\n",
      "\n",
      "Total columns: 29\n",
      "\n",
      "Review text columns found:\n",
      "['review1_text', 'review2_text', 'review3_text', 'review4_text', 'review5_text']\n",
      "\n",
      "Restaurant identifier columns: place_id, name\n"
     ]
    }
   ],
   "source": [
    "# Inspect reviews dataset\n",
    "reviews_sample = pd.read_csv('mcgill_restaurant_reviews.csv', nrows=2)\n",
    "print(\"Reviews CSV Columns:\")\n",
    "print(reviews_sample.columns.tolist())\n",
    "print(f\"\\nTotal columns: {len(reviews_sample.columns)}\")\n",
    "print(\"\\nReview text columns found:\")\n",
    "review_cols = [col for col in reviews_sample.columns if col.startswith('review') and col.endswith('_text')]\n",
    "print(review_cols)\n",
    "print(f\"\\nRestaurant identifier columns: place_id, name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon CSV Columns: ['Word', 'Score']\n",
      "\n",
      "Total lexicon entries: 109\n",
      "\n",
      "Score range: -5 to 5\n",
      "\n",
      "Sample entries:\n",
      "              Word  Score\n",
      "0            cheap      4\n",
      "1       affordable      3\n",
      "2           budget      3\n",
      "3  budget-friendly      4\n",
      "4      inexpensive      3\n",
      "5         low-cost      3\n",
      "6       reasonable      2\n",
      "7             fair      2\n",
      "8             deal      3\n",
      "9          bargain      4\n",
      "\n",
      "Multiword phrases (sample):\n",
      "                       Word  Score\n",
      "66      cheap and delicious      5\n",
      "67              great value      5\n",
      "68        worth every penny      5\n",
      "69    amazing for the price      5\n",
      "70         super affordable      5\n",
      "71       fire for the price      5\n",
      "72   cheap but high quality      5\n",
      "73  best bang for your buck      5\n",
      "74       bang for your buck      5\n",
      "75      insanely good value      5\n"
     ]
    }
   ],
   "source": [
    "# Inspect custom lexicon\n",
    "lexicon_df = pd.read_csv('complete_lexicon.csv')\n",
    "print(\"Lexicon CSV Columns:\", lexicon_df.columns.tolist())\n",
    "print(f\"\\nTotal lexicon entries: {len(lexicon_df)}\")\n",
    "print(f\"\\nScore range: {lexicon_df['Score'].min()} to {lexicon_df['Score'].max()}\")\n",
    "print(\"\\nSample entries:\")\n",
    "print(lexicon_df.head(10))\n",
    "print(\"\\nMultiword phrases (sample):\")\n",
    "multiword = lexicon_df[lexicon_df['Word'].str.contains(' ', na=False)]\n",
    "print(multiword.head(10) if len(multiword) > 0 else \"No multiword phrases found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for data loading, lexicon processing, and sentiment scoring.\n",
    "def load_and_reshape_reviews(csv_path, filter_hotels=True):\n",
    "    \"\"\"\n",
    "    Load reviews CSV and reshape to one row per review.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the reviews CSV file\n",
    "        filter_hotels: If True, exclude hotels (primary_type == 'hotel')\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Filter out hotels if requested\n",
    "    if filter_hotels:\n",
    "        original_count = len(df)\n",
    "        df = df[df['primary_type'] != 'hotel'].copy()\n",
    "        filtered_count = len(df)\n",
    "        print(f\"Filtered out {original_count - filtered_count} hotels, keeping {filtered_count} restaurants/cafes\")\n",
    "    \n",
    "    # Deduplicate by place_id (keep first occurrence only)\n",
    "    # This ensures each place has exactly 5 reviews (one row per place)\n",
    "    before_dedup = len(df)\n",
    "    df = df.drop_duplicates(subset=['place_id'], keep='first').copy()\n",
    "    after_dedup = len(df)\n",
    "    if before_dedup > after_dedup:\n",
    "        print(f\"Deduplicated: removed {before_dedup - after_dedup} duplicate place entries\")\n",
    "    \n",
    "    # Extract all review columns\n",
    "    review_cols = [col for col in df.columns if col.startswith('review') and col.endswith('_text')]\n",
    "    \n",
    "    # Reshape: create one row per review\n",
    "    reviews_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        place_id = row['place_id']\n",
    "        name = row['name']\n",
    "        rating = row.get('rating', np.nan)\n",
    "        primary_type = row.get('primary_type', '')\n",
    "        \n",
    "        for review_col in review_cols:\n",
    "            review_text = row[review_col]\n",
    "            if pd.notna(review_text) and str(review_text).strip():\n",
    "                # Extract review number\n",
    "                review_num = review_col.replace('review', '').replace('_text', '')\n",
    "                review_rating = row.get(f'review{review_num}_rating', np.nan)\n",
    "                review_author = row.get(f'review{review_num}_author', np.nan)\n",
    "                \n",
    "                reviews_list.append({\n",
    "                    'place_id': place_id,\n",
    "                    'restaurant_name': name,\n",
    "                    'primary_type': primary_type,\n",
    "                    'restaurant_rating': rating,\n",
    "                    'review_text': review_text,\n",
    "                    'review_rating': review_rating,\n",
    "                    'review_author': review_author,\n",
    "                    'review_number': review_num\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(reviews_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_custom_lexicon(csv_path):\n",
    "    \"\"\"\n",
    "    Load custom lexicon and return as two dicts:\n",
    "    - single_words: {word: score} for single tokens\n",
    "    - multiword_phrases: {phrase: score} for multiword phrases\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    single_words = {}\n",
    "    multiword_phrases = {}\n",
    "    \n",
    "    # Handle different column name possibilities\n",
    "    word_col = 'Word' if 'Word' in df.columns else 'Phrase'\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        word = str(row[word_col]).strip().lower()\n",
    "        score = float(row['Score'])\n",
    "        \n",
    "        # Check if it's a multiword phrase (contains space)\n",
    "        if ' ' in word:\n",
    "            multiword_phrases[word] = score\n",
    "        else:\n",
    "            single_words[word] = score\n",
    "    \n",
    "    return single_words, multiword_phrases\n",
    "\n",
    "def load_all_lexicons():\n",
    "    \"\"\"\n",
    "    Load all lexicons (English and French) and combine them.\n",
    "    Returns: (single_words, multiword_phrases) dicts with all terms combined.\n",
    "    \"\"\"\n",
    "    # Load English lexicon\n",
    "    eng_single, eng_phrases = load_custom_lexicon('complete_lexicon.csv')\n",
    "    \n",
    "    # Load French Montreal lexicon (combined single words and phrases)\n",
    "    df_french = pd.read_excel('lexicon_french_montreal.xlsx')\n",
    "    fr_single = {}\n",
    "    fr_phrases = {}\n",
    "    \n",
    "    # Handle different column name possibilities\n",
    "    word_col = 'Word' if 'Word' in df_french.columns else 'Phrase'\n",
    "    \n",
    "    for _, row in df_french.iterrows():\n",
    "        word = str(row[word_col]).strip().lower()\n",
    "        score = float(row['Score'])\n",
    "        \n",
    "        # Check if it's a multiword phrase (contains space)\n",
    "        if ' ' in word:\n",
    "            fr_phrases[word] = score\n",
    "        else:\n",
    "            fr_single[word] = score\n",
    "    \n",
    "    # Combine all lexicons\n",
    "    all_single_words = {**eng_single, **fr_single}\n",
    "    all_multiword_phrases = {**eng_phrases, **fr_phrases}\n",
    "    \n",
    "    return all_single_words, all_multiword_phrases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_overlap(vader_analyzer, custom_single_words):\n",
    "    \"\"\"Identify terms that appear in both VADER and custom lexicon.\"\"\"\n",
    "    vader_lexicon = vader_analyzer.lexicon\n",
    "    overlap = set(vader_lexicon.keys()) & set(custom_single_words.keys())\n",
    "    return overlap\n",
    "\n",
    "def create_modified_vader(custom_single_words, override=True):\n",
    "    \"\"\"\n",
    "    Create VADER analyzer with custom lexicon integration.\n",
    "    Only single words can be added to VADER's lexicon.\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    if override:\n",
    "        # Add/override custom lexicon entries (single words only)\n",
    "        for word, score in custom_single_words.items():\n",
    "            # Normalize score to VADER's scale (-4 to +4)\n",
    "            # Custom lexicon uses -5 to +5, so we scale proportionally\n",
    "            vader_score = (score / 5.0) * 4.0\n",
    "            analyzer.lexicon[word] = vader_score\n",
    "    \n",
    "    return analyzer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring functions\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text while preserving punctuation and emojis for VADER.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    # Remove excessive whitespace but keep single spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def score_review(analyzer, text, custom_single_words, custom_multiword_phrases):\n",
    "    \"\"\"\n",
    "    Score a review using VADER with custom lexicon.\n",
    "    Handles both single words (via VADER lexicon) and multiword phrases (via post-processing).\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    if not cleaned:\n",
    "        return {\n",
    "            'compound': 0.0,\n",
    "            'pos': 0.0,\n",
    "            'neu': 1.0,\n",
    "            'neg': 0.0,\n",
    "            'custom_terms_found': []\n",
    "        }\n",
    "    \n",
    "    # Get VADER scores (includes single-word custom lexicon entries)\n",
    "    scores = analyzer.polarity_scores(cleaned)\n",
    "    \n",
    "    # Track custom lexicon terms found and adjust for multiword phrases\n",
    "    text_lower = cleaned.lower()\n",
    "    custom_terms_found = []\n",
    "    phrase_adjustment = 0.0\n",
    "    \n",
    "    # Check single words\n",
    "    for term in custom_single_words.keys():\n",
    "        if term in text_lower:\n",
    "            custom_terms_found.append(term)\n",
    "    \n",
    "    # Check multiword phrases and apply adjustment\n",
    "    for phrase, score in custom_multiword_phrases.items():\n",
    "        if phrase in text_lower:\n",
    "            custom_terms_found.append(phrase)\n",
    "            # Normalize phrase score to VADER compound scale and apply weighted adjustment\n",
    "            phrase_compound = (score / 5.0) * 0.3  # Scale to compound range and weight\n",
    "            phrase_adjustment += phrase_compound\n",
    "    \n",
    "    # Apply phrase adjustment (clamp to [-1, 1] range)\n",
    "    adjusted_compound = np.clip(scores['compound'] + phrase_adjustment, -1.0, 1.0)\n",
    "    \n",
    "    return {\n",
    "        'compound': adjusted_compound,\n",
    "        'pos': scores['pos'],\n",
    "        'neu': scores['neu'],\n",
    "        'neg': scores['neg'],\n",
    "        'custom_terms_found': custom_terms_found\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 3 hotels, keeping 105 restaurants/cafes\n",
      "Deduplicated: removed 15 duplicate place entries\n",
      "\n",
      " Loaded 450 reviews from 90 restaurants/cafes\n",
      " Loaded 85 single-word entries (English + French)\n",
      " Loaded 46 multiword phrases (English + French)\n",
      "\n",
      " Validation passed: All 90 places have exactly 5 reviews\n",
      "\n",
      "Sample reviews:\n",
      "     restaurant_name         primary_type  \\\n",
      "0  Crusty's Downtown  american_restaurant   \n",
      "1  Crusty's Downtown  american_restaurant   \n",
      "2  Crusty's Downtown  american_restaurant   \n",
      "\n",
      "                                         review_text  \n",
      "0  Lucky me, I found this spot close to my hotel ...  \n",
      "1  Owner was very helpful and patient. Food was s...  \n",
      "2  Amazing spot with lots of seating and good dec...  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "reviews_df = load_and_reshape_reviews('mcgill_restaurant_reviews.csv', filter_hotels=True)\n",
    "custom_single_words, custom_multiword_phrases = load_all_lexicons()\n",
    "\n",
    "print(f\"\\n Loaded {len(reviews_df)} reviews from {reviews_df['place_id'].nunique()} restaurants/cafes\")\n",
    "print(f\" Loaded {len(custom_single_words)} single-word entries (English + French)\")\n",
    "print(f\" Loaded {len(custom_multiword_phrases)} multiword phrases (English + French)\")\n",
    "\n",
    "# Validate: Check that each place has exactly 5 reviews\n",
    "review_counts = reviews_df.groupby('place_id').size()\n",
    "places_with_wrong_count = review_counts[review_counts != 5]\n",
    "if len(places_with_wrong_count) > 0:\n",
    "    print(f\"\\n  WARNING: {len(places_with_wrong_count)} places don't have exactly 5 reviews:\")\n",
    "    print(places_with_wrong_count.head(10))\n",
    "    # Show which places have issues\n",
    "    problem_places = reviews_df[reviews_df['place_id'].isin(places_with_wrong_count.index)]\n",
    "    print(\"\\nProblem places:\")\n",
    "    print(problem_places[['place_id', 'restaurant_name']].drop_duplicates())\n",
    "else:\n",
    "    print(f\"\\n Validation passed: All {reviews_df['place_id'].nunique()} places have exactly 5 reviews\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample reviews:\")\n",
    "print(reviews_df[['restaurant_name', 'primary_type', 'review_text']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics Modeling Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sentiment analyzer...\n",
      "\n",
      " Found 85 overlapping terms between VADER and custom lexicon\n",
      "Sample overlaps: ['legit', 'flavorful', 'low-cost', 'perfect', 'inflated', 'kind', 'fresh', 'soggy', 'frais', 'pricey']\n"
     ]
    }
   ],
   "source": [
    "# Create analyzer\n",
    "#Initialize VADER with custom lexicon integration and identify overlaps.\n",
    "#If a token/phrase appears in both VADER and custom lexicon, use the custom lexicon score\n",
    "print(\"Creating sentiment analyzer...\")\n",
    "analyzer = create_modified_vader(custom_single_words, override=True)\n",
    "\n",
    "# Identify overlap\n",
    "overlap = identify_overlap(analyzer, custom_single_words)\n",
    "print(f\"\\n Found {len(overlap)} overlapping terms between VADER and custom lexicon\")\n",
    "if len(overlap) > 0:\n",
    "    print(f\"Sample overlaps: {list(overlap)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring reviews...\n",
      "\n",
      " Scored 450 reviews\n",
      "\n",
      "Sample results:\n",
      "     restaurant_name  compound  compound_vader_baseline  custom_terms_count\n",
      "0  Crusty's Downtown    0.9749                   0.9784                   2\n",
      "1  Crusty's Downtown    0.9652                   0.9459                   5\n",
      "2  Crusty's Downtown    0.9555                   0.9551                   2\n",
      "3  Crusty's Downtown    0.9489                   0.9568                   3\n",
      "4  Crusty's Downtown    0.7506                   0.7717                   1\n"
     ]
    }
   ],
   "source": [
    "# Score Reviews\n",
    "# Apply sentiment analysis to all reviews\n",
    "\n",
    "# Create baseline VADER analyzer (without custom lexicon)\n",
    "baseline_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Score reviews\n",
    "print(\"Scoring reviews...\")\n",
    "results = []\n",
    "for idx, row in reviews_df.iterrows():\n",
    "    # Custom VADER (with GenZ lexicon)\n",
    "    scores = score_review(analyzer, row['review_text'], custom_single_words, custom_multiword_phrases)\n",
    "    \n",
    "    # Baseline VADER (standard - no custom lexicon)\n",
    "    baseline_scores = baseline_analyzer.polarity_scores(clean_text(row['review_text']))\n",
    "    \n",
    "    results.append({\n",
    "        'place_id': row['place_id'],\n",
    "        'restaurant_name': row['restaurant_name'],\n",
    "        'review_text': row['review_text'],\n",
    "        'review_rating': row['review_rating'],\n",
    "        'compound': scores['compound'],\n",
    "        'positive': scores['pos'],\n",
    "        'neutral': scores['neu'],\n",
    "        'negative': scores['neg'],\n",
    "        'compound_vader_baseline': baseline_scores['compound'],\n",
    "        'custom_terms_count': len(scores['custom_terms_found']),\n",
    "        'custom_terms': ', '.join(scores['custom_terms_found'][:5])  # First 5 for display\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n Scored {len(results_df)} reviews\")\n",
    "print(\"\\nSample results:\")\n",
    "print(results_df[['restaurant_name', 'compound', 'compound_vader_baseline', 'custom_terms_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Aggregated 90 restaurants\n",
      "\n",
      "Top 5 most positive restaurants (Custom Lexicon, VADER, and Google Maps ratings):\n",
      "                 restaurant_name  sentiment_score_1_5_custom  \\\n",
      "77              Restaurant Zante                        4.96   \n",
      "75  Café Olimpico - Centre-Ville                        4.96   \n",
      "74              Lola Rosa Milton                        4.95   \n",
      "21         LEAVES HOUSE (McGill)                        4.95   \n",
      "73                           Ryu                        4.95   \n",
      "\n",
      "    sentiment_score_1_5_vader  avg_google_rating  \n",
      "77                       4.95                5.0  \n",
      "75                       4.96                5.0  \n",
      "74                       4.95                5.0  \n",
      "21                       4.95                5.0  \n",
      "73                       4.94                4.8  \n"
     ]
    }
   ],
   "source": [
    "#Restaurant-Level Aggregation\n",
    "#Aggregate sentiment scores to restaurant level\n",
    "\n",
    "# Restaurant-level aggregation\n",
    "\n",
    "restaurant_agg = results_df.groupby(['place_id', 'restaurant_name']).agg({\n",
    "    'compound': ['mean', 'std', 'count'],\n",
    "    'compound_vader_baseline': 'mean',\n",
    "    'positive': 'mean',\n",
    "    'neutral': 'mean',\n",
    "    'negative': 'mean',\n",
    "    'custom_terms_count': 'sum',\n",
    "    'review_rating': 'mean'  # Average Google Maps rating\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "restaurant_agg.columns = [\n",
    "    'place_id', 'restaurant_name', 'mean_compound', 'std_compound', \n",
    "    'review_count', 'mean_compound_vader_baseline', 'mean_positive', 'mean_neutral', 'mean_negative', \n",
    "    'total_custom_terms', 'avg_google_rating'\n",
    "]\n",
    "\n",
    "# Convert compound score (-1 to +1) to 1-5 scale for comparison\n",
    "# Linear mapping: compound -1.0 → 1.0, 0.0 → 3.0, +1.0 → 5.0\n",
    "# Note: This uses custom lexicon (English GenZ + French Montreal combined)\n",
    "restaurant_agg['sentiment_score_1_5_custom'] = 3 + (restaurant_agg['mean_compound'] * 2)\n",
    "restaurant_agg['sentiment_score_1_5_custom'] = restaurant_agg['sentiment_score_1_5_custom'].round(2)\n",
    "\n",
    "# Convert baseline VADER compound score to 1-5 scale\n",
    "restaurant_agg['sentiment_score_1_5_vader'] = 3 + (restaurant_agg['mean_compound_vader_baseline'] * 2)\n",
    "restaurant_agg['sentiment_score_1_5_vader'] = restaurant_agg['sentiment_score_1_5_vader'].round(2)\n",
    "\n",
    "# Calculate difference between Custom sentiment score and Google rating\n",
    "restaurant_agg['score_difference_custom'] = restaurant_agg['sentiment_score_1_5_custom'] - restaurant_agg['avg_google_rating']\n",
    "restaurant_agg['score_difference_custom'] = restaurant_agg['score_difference_custom'].round(2)\n",
    "\n",
    "# Calculate difference between baseline VADER and Google rating\n",
    "restaurant_agg['score_difference_vader'] = restaurant_agg['sentiment_score_1_5_vader'] - restaurant_agg['avg_google_rating']\n",
    "restaurant_agg['score_difference_vader'] = restaurant_agg['score_difference_vader'].round(2)\n",
    "\n",
    "restaurant_agg = restaurant_agg.sort_values('mean_compound', ascending=False)\n",
    "print(f\"\\n Aggregated {len(restaurant_agg)} restaurants\")\n",
    "print(\"\\nTop 5 most positive restaurants (Custom Lexicon, VADER, and Google Maps ratings):\")\n",
    "print(restaurant_agg[['restaurant_name', 'sentiment_score_1_5_custom', 'sentiment_score_1_5_vader', 'avg_google_rating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "\n",
      "1. Distribution Scores:\n",
      "count    450.000000\n",
      "mean       0.710920\n",
      "std        0.524446\n",
      "min       -1.000000\n",
      "25%        0.759675\n",
      "50%        0.943350\n",
      "75%        0.978900\n",
      "max        1.000000\n",
      "Name: compound, dtype: float64\n",
      "Percentiles: 25%=0.760, 50%=0.943, 75%=0.979\n"
     ]
    }
   ],
   "source": [
    "##Summary Statistics related to results \n",
    "#Add sentiment labels\n",
    "results_df['sentiment_label'] = pd.cut(\n",
    "    results_df['compound'],\n",
    "    bins=[-1, -0.05, 0.05, 1],\n",
    "    labels=['negative', 'neutral', 'positive']\n",
    ")\n",
    "\n",
    "# 1. Distribution of Compound Scores\n",
    "\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "\n",
    "print(\"\\n1. Distribution Scores:\")\n",
    "print(results_df['compound'].describe())\n",
    "print(f\"Percentiles: 25%={results_df['compound'].quantile(0.25):.3f}, \"\n",
    "      f\"50%={results_df['compound'].quantile(0.50):.3f}, \"\n",
    "      f\"75%={results_df['compound'].quantile(0.75):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Sentiment Classification (using compound thresholds):\n",
      "sentiment_label\n",
      "positive    88.418708\n",
      "negative    10.467706\n",
      "neutral      1.113586\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Counts:\n",
      "sentiment_label\n",
      "positive    397\n",
      "negative     47\n",
      "neutral       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Sentiment Classification Distribution\n",
    "print(\"\\n2. Sentiment Classification (using compound thresholds):\")\n",
    "sentiment_dist = results_df['sentiment_label'].value_counts(normalize=True) * 100\n",
    "print(sentiment_dist)\n",
    "print(\"\\nCounts:\")\n",
    "print(results_df['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Custom Lexicon Usage:\n",
      "   Reviews with custom terms: 412 (91.6%)\n",
      "   Total custom terms found: 1353\n",
      "   Average custom terms per review: 3.01\n"
     ]
    }
   ],
   "source": [
    "# 3. Custom Lexicon Usage\n",
    "print(\"\\n3. Custom Lexicon Usage:\")\n",
    "print(f\"   Reviews with custom terms: {(results_df['custom_terms_count'] > 0).sum()} \"\n",
    "      f\"({(results_df['custom_terms_count'] > 0).mean()*100:.1f}%)\")\n",
    "print(f\"   Total custom terms found: {results_df['custom_terms_count'].sum()}\")\n",
    "print(f\"   Average custom terms per review: {results_df['custom_terms_count'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Top 10 Most Positive Restaurants (by sentiment score 1-5):\n",
      "                 restaurant_name  sentiment_score_1_5_custom  avg_google_rating  score_difference_custom  review_count\n",
      "                Restaurant Zante                        4.96                5.0                    -0.04             5\n",
      "    Café Olimpico - Centre-Ville                        4.96                5.0                    -0.04             5\n",
      "                Lola Rosa Milton                        4.95                5.0                    -0.05             5\n",
      "           LEAVES HOUSE (McGill)                        4.95                5.0                    -0.05             5\n",
      "                             Ryu                        4.95                4.8                     0.15             5\n",
      "   Café Humble Lion (Sherbrooke)                        4.95                4.4                     0.55             5\n",
      "          Le Poké Station McGill                        4.95                5.0                    -0.05             5\n",
      "                     Sushi Inbox                        4.94                5.0                    -0.06             5\n",
      "Pizzéria NO.900 - Peel, Montréal                        4.94                4.8                     0.14             5\n",
      "                    Poulet Rouge                        4.94                5.0                    -0.06             5\n"
     ]
    }
   ],
   "source": [
    "# 4. Top 10 Most Positive Restaurants\n",
    "print(\"\\n4. Top 10 Most Positive Restaurants (by sentiment score 1-5):\")\n",
    "top_positive = restaurant_agg.head(10)[['restaurant_name', 'sentiment_score_1_5_custom', 'avg_google_rating', 'score_difference_custom', 'review_count']]\n",
    "print(top_positive.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Bottom 10 Most Negative Restaurants (by sentiment score 1-5):\n",
      "   restaurant_name  sentiment_score_1_5_custom  avg_google_rating  score_difference_custom  review_count\n",
      "        La Cantina                        3.36                3.2                     0.16             5\n",
      "        McDonald's                        3.30                2.8                     0.50             5\n",
      "            Subway                        3.13                2.6                     0.53             5\n",
      "Columbus Café & Co                        3.11                3.2                    -0.09             5\n",
      "       Tim Hortons                        3.07                2.8                     0.27             5\n",
      "          Cultures                        2.98                2.4                     0.58             5\n",
      " Second Cup Coffee                        2.95                3.2                    -0.25             5\n",
      "         Starbucks                        2.64                2.0                     0.64             5\n",
      "        Gert's Bar                        2.20                2.0                     0.20             5\n",
      "       Tim Hortons                        2.12                1.0                     1.12             5\n"
     ]
    }
   ],
   "source": [
    "# 5. Bottom 10 Most Negative Restaurants\n",
    "print(\"\\n5. Bottom 10 Most Negative Restaurants (by sentiment score 1-5):\")\n",
    "bottom_negative = restaurant_agg.tail(10)[['restaurant_name', 'sentiment_score_1_5_custom', 'avg_google_rating', 'score_difference_custom', 'review_count']]\n",
    "print(bottom_negative.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT SCORE vs GOOGLE MAPS RATING COMPARISON\n",
      "\n",
      "Sentiment Score (1-5) Statistics:\n",
      "count    90.000000\n",
      "mean      4.421333\n",
      "std       0.655084\n",
      "min       2.120000\n",
      "25%       4.202500\n",
      "50%       4.685000\n",
      "75%       4.907500\n",
      "max       4.960000\n",
      "Name: sentiment_score_1_5_custom, dtype: float64\n",
      "\n",
      "Google Maps Rating Statistics:\n",
      "count    90.000000\n",
      "mean      4.224444\n",
      "std       0.801026\n",
      "min       1.000000\n",
      "25%       4.000000\n",
      "50%       4.400000\n",
      "75%       4.800000\n",
      "max       5.000000\n",
      "Name: avg_google_rating, dtype: float64\n",
      "\n",
      "Score Difference Statistics (Sentiment - Google):\n",
      "count    90.000000\n",
      "mean      0.196889\n",
      "std       0.351068\n",
      "min      -0.600000\n",
      "25%      -0.057500\n",
      "50%       0.125000\n",
      "75%       0.410000\n",
      "max       1.150000\n",
      "Name: score_difference_custom, dtype: float64\n",
      "\n",
      "   Positive difference = Sentiment score is higher than Google rating\n",
      "   Negative difference = Sentiment score is lower than Google rating\n",
      "\n",
      "Correlation between Sentiment Score and Google Rating: 0.903\n",
      "\n",
      "Restaurants where Sentiment Score is much HIGHER than Google Rating:\n",
      "                    restaurant_name  sentiment_score_1_5_custom  avg_google_rating  score_difference_custom\n",
      "                  Pigeon Café & Bar                        4.15                3.0                     1.15\n",
      "                        Tim Hortons                        2.12                1.0                     1.12\n",
      "                             Le Taj                        4.82                3.8                     1.02\n",
      "           Starbucks Coffee Company                        4.18                3.2                     0.98\n",
      "           Pizzeria Bros (Downtown)                        4.57                3.6                     0.97\n",
      "   Reuben's Restaurant Delicatessen                        4.65                3.8                     0.85\n",
      "                Petit Opus Café-Bar                        4.83                4.0                     0.83\n",
      "Shawarmania Cuisine Mediterraneenne                        4.92                4.2                     0.72\n",
      "          Cafétéria La Mosaïque 墨客轩                        4.72                4.0                     0.72\n",
      "                            Sushiyo                        4.09                3.4                     0.69\n",
      "\n",
      "Restaurants where Sentiment Score is much LOWER than Google Rating:\n",
      "                 restaurant_name  sentiment_score_1_5_custom  avg_google_rating  score_difference_custom\n",
      "                     Osteria mkt                        4.20                4.8                    -0.60\n",
      "                      Vinh's Too                        4.75                5.0                    -0.25\n",
      "               Second Cup Coffee                        2.95                3.2                    -0.25\n",
      "     Restaurant Pizzeria elForne                        4.76                5.0                    -0.24\n",
      "                   Booster Juice                        4.56                4.8                    -0.24\n",
      "                       Alice Bar                        3.97                4.2                    -0.23\n",
      "                     Café Castel                        4.61                4.8                    -0.19\n",
      "              Café Vasco da Gama                        4.42                4.6                    -0.18\n",
      "Universel Déjeuners et Grillades                        4.03                4.2                    -0.17\n",
      "                       Lee N Kim                        4.84                5.0                    -0.16\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Score vs Google Maps Rating Comparison\n",
    "\n",
    "# Comparison statistics\n",
    "\n",
    "print(\"SENTIMENT SCORE vs GOOGLE MAPS RATING COMPARISON\")\n",
    "\n",
    "\n",
    "print(f\"\\nSentiment Score (1-5) Statistics:\")\n",
    "print(restaurant_agg['sentiment_score_1_5_custom'].describe())\n",
    "\n",
    "print(f\"\\nGoogle Maps Rating Statistics:\")\n",
    "print(restaurant_agg['avg_google_rating'].describe())\n",
    "\n",
    "print(f\"\\nScore Difference Statistics (Sentiment - Google):\")\n",
    "print(restaurant_agg['score_difference_custom'].describe())\n",
    "print(f\"\\n   Positive difference = Sentiment score is higher than Google rating\")\n",
    "print(f\"   Negative difference = Sentiment score is lower than Google rating\")\n",
    "\n",
    "# Correlation\n",
    "correlation = restaurant_agg['sentiment_score_1_5_custom'].corr(restaurant_agg['avg_google_rating'])\n",
    "print(f\"\\nCorrelation between Sentiment Score and Google Rating: {correlation:.3f}\")\n",
    "\n",
    "# Restaurants with largest differences\n",
    "print(\"\\nRestaurants where Sentiment Score is much HIGHER than Google Rating:\")\n",
    "high_diff = restaurant_agg.nlargest(10, 'score_difference_custom')[['restaurant_name', 'sentiment_score_1_5_custom', 'avg_google_rating', 'score_difference_custom']]\n",
    "print(high_diff.to_string(index=False))\n",
    "\n",
    "print(\"\\nRestaurants where Sentiment Score is much LOWER than Google Rating:\")\n",
    "low_diff = restaurant_agg.nsmallest(10, 'score_difference_custom')[['restaurant_name', 'sentiment_score_1_5_custom', 'avg_google_rating', 'score_difference_custom']]\n",
    "print(low_diff.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION: Custom Lexicon Impact\n",
      "\n",
      "Found 412 reviews where custom lexicon had an impact\n",
      "\n",
      "Example reviews where custom lexicon changed the result:\n",
      "\n",
      "Example 1:\n",
      "Review: It's expensive for third-quintile coffee: latte wasn't very tasty and mocha was a bit too sweet. Not bad by any means, but not different than what you would get down the street. However, $18 for two d...\n",
      "Baseline VADER: 0.463 (positive)\n",
      "With Custom Lexicon: -0.691 (negative)\n",
      "Difference: -1.155\n",
      "Custom terms found: expensive, steep, tasty, bad\n",
      "\n",
      "Example 2:\n",
      "Review: Location is good and they provide free parking, which is really great for a downtown location however it is very confusing to get to the restaurant from the parking lot because you’re going through a ...\n",
      "Baseline VADER: -0.123 (negative)\n",
      "With Custom Lexicon: -0.786 (negative)\n",
      "Difference: -0.664\n",
      "Custom terms found: great, good, cold\n",
      "\n",
      "Example 3:\n",
      "Review: The service was fast and efficient. Attentive and present\n",
      "\n",
      "We generally liked everything but nothing was wow. Fresh tuna in the tartar. Spicy chicken burger was good but not very tender. I enjoyed the...\n",
      "Baseline VADER: 0.233 (positive)\n",
      "With Custom Lexicon: -0.388 (negative)\n",
      "Difference: -0.621\n",
      "Custom terms found: fresh, good\n"
     ]
    }
   ],
   "source": [
    "#Validation: Custom Lexicon Impact\n",
    "#Compare results with baseline VADER to show where custom lexicon changes the outcome.\n",
    "\n",
    "# Create baseline VADER (without custom lexicon)\n",
    "baseline_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Find reviews where custom lexicon changes the result\n",
    "\n",
    "print(\"VALIDATION: Custom Lexicon Impact\")\n",
    "\n",
    "\n",
    "comparison_results = []\n",
    "for idx, row in results_df.iterrows():\n",
    "    baseline_scores = baseline_analyzer.polarity_scores(clean_text(row['review_text']))\n",
    "    baseline_compound = baseline_scores['compound']\n",
    "    custom_compound = row['compound']\n",
    "    \n",
    "    # Check if sentiment label changed\n",
    "    baseline_label = 'negative' if baseline_compound < -0.05 else ('positive' if baseline_compound > 0.05 else 'neutral')\n",
    "    custom_label = row['sentiment_label']\n",
    "    \n",
    "    # Include if label changed OR significant difference OR custom terms were found\n",
    "    if baseline_label != custom_label or abs(baseline_compound - custom_compound) > 0.1 or row['custom_terms_count'] > 0:\n",
    "        comparison_results.append({\n",
    "            'review_text': row['review_text'][:200] + '...' if len(row['review_text']) > 200 else row['review_text'],\n",
    "            'baseline_compound': baseline_compound,\n",
    "            'custom_compound': custom_compound,\n",
    "            'baseline_label': baseline_label,\n",
    "            'custom_label': custom_label,\n",
    "            'difference': custom_compound - baseline_compound,\n",
    "            'custom_terms': row['custom_terms']\n",
    "        })\n",
    "\n",
    "if comparison_results:\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    comparison_df = comparison_df.sort_values('difference', key=abs, ascending=False)\n",
    "    \n",
    "    print(f\"\\nFound {len(comparison_df)} reviews where custom lexicon had an impact\")\n",
    "    print(\"\\nExample reviews where custom lexicon changed the result:\")\n",
    "    \n",
    "    for i, row in comparison_df.head(3).iterrows():\n",
    "        print(f\"\\nExample {list(comparison_df.index).index(i) + 1}:\")\n",
    "        print(f\"Review: {row['review_text']}\")\n",
    "        print(f\"Baseline VADER: {row['baseline_compound']:.3f} ({row['baseline_label']})\")\n",
    "        print(f\"With Custom Lexicon: {row['custom_compound']:.3f} ({row['custom_label']})\")\n",
    "        print(f\"Difference: {row['difference']:+.3f}\")\n",
    "        print(f\"Custom terms found: {row['custom_terms']}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nNo significant differences found between baseline and custom lexicon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUSPICIOUS OUTCOME CHECKS\n",
      "\n",
      "Neutral reviews: 1.1% (acceptable)\n",
      "\n",
      "Compound score std: 0.524 (acceptable)\n",
      "\n",
      "Custom lexicon usage: 91.6% of reviews contain custom terms\n"
     ]
    }
   ],
   "source": [
    "#Identify potential issues with the results\n",
    "\n",
    "\n",
    "print(\"SUSPICIOUS OUTCOME CHECKS\")\n",
    "\n",
    "\n",
    "neutral_pct = (results_df['sentiment_label'] == 'neutral').mean() * 100\n",
    "if neutral_pct > 70:\n",
    "    print(f\"\\n  WARNING: {neutral_pct:.1f}% of reviews are neutral. This may indicate:\")\n",
    "    print(\"   - Reviews are too short or lack sentiment-bearing words\")\n",
    "    print(\"   - Lexicon mismatch (terms not appearing in reviews)\")\n",
    "    print(\"   - Suggestion: Check if custom lexicon terms are actually present in reviews\")\n",
    "else:\n",
    "    print(f\"\\nNeutral reviews: {neutral_pct:.1f}% (acceptable)\")\n",
    "\n",
    "if results_df['compound'].std() < 0.1:\n",
    "    print(f\"\\n  WARNING: Very low variance in compound scores (std={results_df['compound'].std():.3f})\")\n",
    "    print(\"   - Suggestion: Check if scoring is working correctly\")\n",
    "else:\n",
    "    print(f\"\\nCompound score std: {results_df['compound'].std():.3f} (acceptable)\")\n",
    "\n",
    "custom_usage_pct = (results_df['custom_terms_count'] > 0).mean() * 100\n",
    "if custom_usage_pct < 0.1:\n",
    "    print(f\"\\n  WARNING: Only {custom_usage_pct:.1f}% of reviews contain custom lexicon terms\")\n",
    "    print(\"   - Suggestion: Verify lexicon terms match review vocabulary\")\n",
    "else:\n",
    "    print(f\"\\nCustom lexicon usage: {custom_usage_pct:.1f}% of reviews contain custom terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING COMPREHENSIVE COMPARISON SUMMARY\n",
      "\n",
      " Summary comparison created with the following structure:\n",
      "                     restaurant_name  review_count  google_avg_rating  \\\n",
      "77                  Restaurant Zante             5                5.0   \n",
      "75      Café Olimpico - Centre-Ville             5                5.0   \n",
      "74                  Lola Rosa Milton             5                5.0   \n",
      "21             LEAVES HOUSE (McGill)             5                5.0   \n",
      "73                               Ryu             5                4.8   \n",
      "50     Café Humble Lion (Sherbrooke)             5                4.4   \n",
      "8             Le Poké Station McGill             5                5.0   \n",
      "31                       Sushi Inbox             5                5.0   \n",
      "54  Pizzéria NO.900 - Peel, Montréal             5                4.8   \n",
      "39                      Poulet Rouge             5                5.0   \n",
      "\n",
      "    custom_sentiment_score  vader_sentiment_score  custom_vs_google_diff  \\\n",
      "77                    4.96                   4.95                  -0.04   \n",
      "75                    4.96                   4.96                  -0.04   \n",
      "74                    4.95                   4.95                  -0.05   \n",
      "21                    4.95                   4.95                  -0.05   \n",
      "73                    4.95                   4.94                   0.15   \n",
      "50                    4.95                   4.96                   0.55   \n",
      "8                     4.95                   4.93                  -0.05   \n",
      "31                    4.94                   4.93                  -0.06   \n",
      "54                    4.94                   4.93                   0.14   \n",
      "39                    4.94                   4.92                  -0.06   \n",
      "\n",
      "    vader_vs_google_diff  custom_vs_vader_diff  \n",
      "77                 -0.05                  0.01  \n",
      "75                 -0.04                  0.00  \n",
      "74                 -0.05                  0.00  \n",
      "21                 -0.05                  0.00  \n",
      "73                  0.14                  0.01  \n",
      "50                  0.56                 -0.01  \n",
      "8                  -0.07                  0.02  \n",
      "31                 -0.07                  0.01  \n",
      "54                  0.13                  0.01  \n",
      "39                 -0.08                  0.02  \n",
      "\n",
      "\n",
      "Summary Statistics:\n",
      "\n",
      "Google Rating:\n",
      "  Mean: 4.22\n",
      "  Std:  0.80\n",
      "\n",
      "Custom Lexicon Sentiment Score (1-5 scale):\n",
      "  Mean: 4.42\n",
      "  Std:  0.66\n",
      "\n",
      "VADER Sentiment Score (1-5 scale):\n",
      "  Mean: 4.43\n",
      "  Std:  0.64\n",
      "\n",
      "Differences:\n",
      "  Custom vs Google - Mean: +0.20, Std: 0.35\n",
      "  VADER vs Google - Mean: +0.21, Std: 0.36\n",
      "  Custom vs VADER - Mean: -0.01, Std: 0.11\n"
     ]
    }
   ],
   "source": [
    "#Save Outputs\n",
    "\n",
    "\n",
    "# Create comprehensive comparison summary\n",
    "\n",
    "print(\"CREATING COMPREHENSIVE COMPARISON SUMMARY\")\n",
    "\n",
    "\n",
    "# Calculate difference between Custom and VADER\n",
    "restaurant_agg['custom_vs_vader_difference'] = restaurant_agg['sentiment_score_1_5_custom'] - restaurant_agg['sentiment_score_1_5_vader']\n",
    "restaurant_agg['custom_vs_vader_difference'] = restaurant_agg['custom_vs_vader_difference'].round(2)\n",
    "\n",
    "# Create summary dataframe with all key metrics\n",
    "summary_comparison = restaurant_agg[[\n",
    "    'restaurant_name',\n",
    "    'review_count',\n",
    "    'avg_google_rating',\n",
    "    'sentiment_score_1_5_custom',\n",
    "    'sentiment_score_1_5_vader',\n",
    "    'score_difference_custom',\n",
    "    'score_difference_vader',\n",
    "    'custom_vs_vader_difference'\n",
    "]].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "summary_comparison.columns = [\n",
    "    'restaurant_name',\n",
    "    'review_count',\n",
    "    'google_avg_rating',\n",
    "    'custom_sentiment_score',\n",
    "    'vader_sentiment_score',\n",
    "    'custom_vs_google_diff',\n",
    "    'vader_vs_google_diff',\n",
    "    'custom_vs_vader_diff'\n",
    "]\n",
    "\n",
    "print(\"\\n Summary comparison created with the following structure:\")\n",
    "print(summary_comparison.head(10))\n",
    "\n",
    "print(\"\\n\\nSummary Statistics:\")\n",
    "print(\"\\nGoogle Rating:\")\n",
    "print(f\"  Mean: {summary_comparison['google_avg_rating'].mean():.2f}\")\n",
    "print(f\"  Std:  {summary_comparison['google_avg_rating'].std():.2f}\")\n",
    "\n",
    "print(\"\\nCustom Lexicon Sentiment Score (1-5 scale):\")\n",
    "print(f\"  Mean: {summary_comparison['custom_sentiment_score'].mean():.2f}\")\n",
    "print(f\"  Std:  {summary_comparison['custom_sentiment_score'].std():.2f}\")\n",
    "\n",
    "print(\"\\nVADER Sentiment Score (1-5 scale):\")\n",
    "print(f\"  Mean: {summary_comparison['vader_sentiment_score'].mean():.2f}\")\n",
    "print(f\"  Std:  {summary_comparison['vader_sentiment_score'].std():.2f}\")\n",
    "\n",
    "print(\"\\nDifferences:\")\n",
    "print(f\"  Custom vs Google - Mean: {summary_comparison['custom_vs_google_diff'].mean():+.2f}, Std: {summary_comparison['custom_vs_google_diff'].std():.2f}\")\n",
    "print(f\"  VADER vs Google - Mean: {summary_comparison['vader_vs_google_diff'].mean():+.2f}, Std: {summary_comparison['vader_vs_google_diff'].std():.2f}\")\n",
    "print(f\"  Custom vs VADER - Mean: {summary_comparison['custom_vs_vader_diff'].mean():+.2f}, Std: {summary_comparison['custom_vs_vader_diff'].std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To download the summary of all the work completed, please remove the # symbols. The document descriptions are as follows:\n",
      "  - review_sentiment_scores.csv: Review-level scores\n",
      "  - restaurant_sentiment_aggregated.csv: Restaurant-level aggregation\n",
      "  - lexicon_comparison_examples.csv: Validation examples\n",
      "The only file to download by default is the summary of all the ratings.\n",
      "Saved comprehensive summary to summary_comparison_all_ratings.csv\n"
     ]
    }
   ],
   "source": [
    "#Export results to CSV files.\n",
    "\n",
    "print(\"To download the summary of all the work completed, please remove the # symbols. The document descriptions are as follows:\")\n",
    "\n",
    "print(\"  - review_sentiment_scores.csv: Review-level scores\")\n",
    "print(\"  - restaurant_sentiment_aggregated.csv: Restaurant-level aggregation\")\n",
    "\n",
    "if comparison_results:\n",
    "    print(\"  - lexicon_comparison_examples.csv: Validation examples\")\n",
    "print(\"The only file to download by default is the summary of all the ratings.\")\n",
    "    \n",
    "# Save review-level results\n",
    "#results_df.to_csv('review_sentiment_scores.csv', index=False)\n",
    "#print(\"Saved review-level results to review_sentiment_scores.csv\")\n",
    "\n",
    "# Save restaurant-level aggregation\n",
    "#restaurant_agg.to_csv('restaurant_sentiment_aggregated.csv', index=False)\n",
    "#print(\"Saved restaurant-level results to restaurant_sentiment_aggregated.csv\")\n",
    "\n",
    "# Save comprehensive summary comparison\n",
    "summary_comparison.to_csv('summary_comparison_all_ratings.csv', index=False)\n",
    "print(\"Saved comprehensive summary to summary_comparison_all_ratings.csv\")\n",
    "\n",
    "# Save validation examples if available\n",
    "#if comparison_results:\n",
    " #   comparison_df.to_csv('lexicon_comparison_examples.csv', index=False)\n",
    " #   print(\"✓ Saved validation examples to lexicon_comparison_examples.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional - Rank Correlation Analysis\n",
    "\n",
    "Rank correlation measures whether two variables have a monotonic relationship (if one increases, the other tends to consistently increase or decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK CORRELATION ANALYSIS (SPEARMAN)\n",
      "\n",
      "Custom Lexicon Sentiment Score ↔ Google Rating:\n",
      "  ρ (rho) = 0.7945\n",
      "  p-value = 0.000000\n",
      "  Interpretation: SIGNIFICANT (α=0.05)\n",
      "\n",
      "VADER Sentiment Score ↔ Google Rating:\n",
      "  ρ (rho) = 0.7473\n",
      "  p-value = 0.000000\n",
      "  Interpretation: SIGNIFICANT (α=0.05)\n",
      "\n",
      "Custom Lexicon vs VADER Sentiment Scores:\n",
      "  ρ (rho) = 0.9693\n",
      "  p-value = 0.000000\n",
      "  Interpretation: SIGNIFICANT (α=0.05)\n",
      "\n",
      "\n",
      "SUMMARY TABLE: SPEARMAN'S RANK CORRELATION\n",
      "     Comparison  Spearman ρ      p-value Significance\n",
      "Custom ↔ Google    0.794467 9.237328e-21          YES\n",
      " VADER ↔ Google    0.747342 2.674896e-17          YES\n",
      " Custom ↔ VADER    0.969298 2.122714e-55          YES\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "print(\"RANK CORRELATION ANALYSIS (SPEARMAN)\")\n",
    "\n",
    "\n",
    "\n",
    "# GenZ vs Google Rating\n",
    "spearman_custom_google, p_value_custom_google = spearmanr(\n",
    "    summary_comparison['custom_sentiment_score'],\n",
    "    summary_comparison['google_avg_rating']\n",
    ")\n",
    "print(f\"\\nCustom Lexicon Sentiment Score ↔ Google Rating:\")\n",
    "print(f\"  ρ (rho) = {spearman_custom_google:.4f}\")\n",
    "print(f\"  p-value = {p_value_custom_google:.6f}\")\n",
    "print(f\"  Interpretation: {'SIGNIFICANT' if p_value_custom_google < 0.05 else 'NOT significant'} (α=0.05)\")\n",
    "\n",
    "# VADER vs Google Rating\n",
    "spearman_vader_google, p_value_vader_google = spearmanr(\n",
    "    summary_comparison['vader_sentiment_score'],\n",
    "    summary_comparison['google_avg_rating']\n",
    ")\n",
    "print(f\"\\nVADER Sentiment Score ↔ Google Rating:\")\n",
    "print(f\"  ρ (rho) = {spearman_vader_google:.4f}\")\n",
    "print(f\"  p-value = {p_value_vader_google:.6f}\")\n",
    "print(f\"  Interpretation: {'SIGNIFICANT' if p_value_vader_google < 0.05 else 'NOT significant'} (α=0.05)\")\n",
    "\n",
    "# GenZ vs VADER\n",
    "spearman_custom_vader, p_value_custom_vader = spearmanr(\n",
    "    summary_comparison['custom_sentiment_score'],\n",
    "    summary_comparison['vader_sentiment_score']\n",
    ")\n",
    "print(f\"\\nCustom Lexicon vs VADER Sentiment Scores:\")\n",
    "print(f\"  ρ (rho) = {spearman_custom_vader:.4f}\")\n",
    "print(f\"  p-value = {p_value_custom_vader:.6f}\")\n",
    "print(f\"  Interpretation: {'SIGNIFICANT' if p_value_custom_vader < 0.05 else 'NOT significant'} (α=0.05)\")\n",
    "\n",
    "# Summary table of Spearman correlations\n",
    "print(\"\\n\\nSUMMARY TABLE: SPEARMAN'S RANK CORRELATION\")\n",
    "\n",
    "correlation_summary = pd.DataFrame({\n",
    "    'Comparison': [\n",
    "        'Custom ↔ Google',\n",
    "        'VADER ↔ Google', \n",
    "        'Custom ↔ VADER'\n",
    "    ],\n",
    "    'Spearman ρ': [spearman_custom_google, spearman_vader_google, spearman_custom_vader],\n",
    "    'p-value': [p_value_custom_google, p_value_vader_google, p_value_custom_vader],\n",
    "    'Significance': [\n",
    "        'YES' if p_value_custom_google < 0.05 else 'NO',\n",
    "        'YES' if p_value_vader_google < 0.05 else 'NO',\n",
    "        'YES' if p_value_custom_vader < 0.05 else 'NO'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(correlation_summary.to_string(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Custom GenZ Lexicon and VADER methods show very strong ranking consistency (ρ=0.9693, p=0.000000). Despite using different vocabularies, both methods rank restaurants almost identically, suggesting that standard VADER already captures Gen Z sentiment reasonably well for this dataset.\n",
    "strongly aligns with Google ratings (ρ=0.7945, p=0.000000). Text-based sentiment extraction via the custom lexicon validates the star ratings reviewers provide, suggesting review text and numeric ratings capture similar underlying sentiment.\n",
    "\n",
    "Incorporating Gen Z slang and Montreal French expressions helped slightly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (invoice_env)",
   "language": "python",
   "name": "invoice_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
